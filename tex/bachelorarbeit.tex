% Vorlage für eine Bachelorarbeit
% Siehe auch LaTeX-Kurs von Mathematik-Online
% www.mathematik-online.org/kurse
% Anpassungen für die Fakultät für Mathematik
% am KIT durch Klaus Spitzmüller und Roland Schnaubelt Dezember 2011

\documentclass[12pt,a4paper]{scrartcl}
% scrartcl ist eine abgeleitete Artikel-Klasse im Koma-Skript
% zur Kontrolle des Umbruchs Klassenoption draft verwenden


% die folgenden Packete erlauben den Gebrauch von Umlauten und ß
% in der Latex Datei
\usepackage[utf8]{inputenc}
% \usepackage[latin1]{inputenc} %  Alternativ unter Windows
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}

\usepackage{scrpage2}
\usepackage[pdftex]{graphicx}
\usepackage{latexsym}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{latexsym}
\usepackage{amssymb}


% Abstand obere Blattkante zur Kopfzeile ist 2.54cm - 15mm
\setlength{\topmargin}{-15mm}


% Umgebungen für Definitionen, Sätze, usw.
% Es werden Sätze, Definitionen etc innerhalb einer Section mit
% 1.1, 1.2 etc durchnummeriert, ebenso die Gleichungen mit (1.1), (1.2) ..
\newtheorem{Satz}{Satz}[section]
\newtheorem{Definition}[Satz]{Definition} 
\newtheorem{Lemma}[Satz]{Lemma}	
\newtheorem{Beweis}{Beweis}	
                  
\numberwithin{equation}{section} 

% einige Abkuerzungen
\newcommand{\C}{\mathbb{C}} % komplexe
\newcommand{\K}{\mathbb{K}} % komplexe
\newcommand{\R}{\mathbb{R}} % reelle
\newcommand{\Q}{\mathbb{Q}} % rationale
\newcommand{\Z}{\mathbb{Z}} % ganze
\newcommand{\N}{\mathbb{N}} % natuerliche



\begin{document}
  % Keine Seitenzahlen im Vorspann
  \pagestyle{empty}

  % Titelblatt der Arbeit
  \begin{titlepage}

    \includegraphics[scale=0.45]{logo.png} 
    \vspace*{2cm} 

 \begin{center} \large 
    
    Bachelorarbeit
    \vspace*{2cm}

    {\huge Numerische Analyse des TrueSkill Verfahrens}
    \vspace*{2.5cm}

    Johannes Loevenich
    \vspace*{1.5cm}

    Datum der Abgabe
    \vspace*{4.5cm}


    Betreuung: Prof. Dr. Jochen Garcke \\[1cm]
    Fakultät für Mathematik \\
		Rheinische Friedrich-Wilhelms- Universität Bonn 
  \end{center}
\end{titlepage}



  % Inhaltsverzeichnis
  \tableofcontents

\newpage
 


  % Ab sofort Seitenzahlen in der Kopfzeile anzeigen
  \pagestyle{useheadings}

\section{Einleitung}

Das Problem n Spieler zu bewerten ist ein wichtiger Forschungsbereich des Maschinellen Lernens. \\
Aus der Kombinatorik lässt sich schnell herleiten, dass es $n!$ verschiedene Möglichkeiten gibt n Spieler in einem Ranking zu bewerten. 
Ziel ist es das eine Ranking zu finden, welches das tatsächliche Können der einzelnen Spieler am besten wiederspiegelt. 
Nimmt man an, dass alle Rankings gleich wahrscheinlich sind, so würde dies bedeuten, dass $log_{2}(n!) \approx nlog_{2}(n)$ Spielausgänge nötig wären, um die 
korrekte Bewertung zu ermitteln. 
Diese Schranke ist jedoch nur dann aussagekräftig, falls die Ausgänge eines jeden Spiels gleichverteilt sind. Bei vielen Spielen wird durch das matchen von nahezu gleich
starken Gegnern versucht diese Chancengleichheit zu erzwingen. In dieser Arbeit wird eine Wahrscheinlichkeitstheoretische Interpretation dieses Problems betrachtet, weshalb es 
im weiteren Verlauf von Bedeutung ist gewisse Unsicherheiten in Rang eines Spielers zu berücksichtigen. Interessanterweise reduziert sich die minimale Anzahl von aussagekräftigen
Spielen auf $nlog_{2}(m)$, wenn wir annehmen, dass es $m \ll n$ Äquivalenzklassen oder Level gibt. \\
Betrachten wir Spiele bei denen $k$ Teams gegeneinander antreten und bewertet werden, dann erfüllt jedes Spiel $log_{2}(k)$ Ausgänge und es werden nur $\frac{nlog_{2}(n)}{log_{2}(k!)}$
aussagekräftige Spielausgänge benötigt. 
Man wird sehen, dass das hier vorgestellte Verfahren für das betrachtete Problem nahezu optimal ist, also bis auf geringe Abweichungen gegen die oben genannten Schranken konvergiert. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \newpage  % neuer Abschnitt auf neue Seite, kann auch entfallen
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Das Ranking Problem}

In dieser Arbeit werden Spiele betrachtet, bei denen mehrere Teilnehmende Teams bewertet werden sollen. Falls zwei Spieler oder Teams dieselbe Bewertung erhalten, sagen wir das 
das Spiel unentschieden ausgegangen ist. 
Im Spezialfall von zwei Teams gibt es genau drei mögliche Spielausgänge: Sieg, Niederlage oder unentschieden. \\
Nummerieren wir alle teilnehmenden Spieler eines Spiels von Eins bis n, so kann ein Spiel zwischen $k$ Teams vollständig durch die $k$ Indizes $i_{j} \in \{ 1,...,n \} $ der $n_{j}$ Spieler
im $j$-ten Team beschrieben werden. Der von jedem Team erreichte Rang sei dann definiert als $\textbf{r}:= (r_{1},...,r_{k})^T \in \{ 1,...k \}^{k}$. Es wird davon ausgegangen, dass
dass der Gewinner eines Spiels den Rang 1 erhält. \\
Gesucht wird nach dem Skill $s_{i}$ eines jeden Spielers, $\textbf{s} \in \R^{n}$; wobei der Skill des $j$-ten Teams eine Funktion $S(s_{i_j})$ in Abhängigkeit aller Skills
der Spieler des Teams ist. Im trivialen Fall, dass jedes Team nur einen Spieler enthält beschreibt $S(s_{i}) = s_{i}$ also die Identität.
Für Skills wird die folgende Eigenschaft gefordert. 

\begin{Definition}\textbf{(Stochastische Transitivität)}
Falls ein Team $u$ vor einem Team $v$ platziert wurde, so ist es wahrscheinlicher, dass Team $u$ gegen Team $v$ gewinnt als umgekehrt.

\begin{equation}
 S(s_{i_{u}}) \geq S(s_{i_{v}}) \Rightarrow P(\text{ Team u gewinnt }) > P(\text{ Team v gewinnt })
\end{equation}


\end{Definition}



\section{Wahrscheinlichkeitstheorie}
Dieses Kapitel gibt einen Überblick über einige wichtige Konzepte der Wahrscheinlichkeitstheorie.
Im Folgenden werden Mengen mit Großbuchstaben, z.B. $X$, und deren Elemente mit Kleinbuchstaben, z.B $x$,
bezeichnet. Für Mengen definiere die Indikatorfunktion $I_{X}$ durch 
$$
I_{X}(x) := \begin{cases}0&\text{falls }x\notin X\\1&\text{falls }x \in X\end{cases}
$$

\begin{Definition}\textbf{($\sigma$-Algebra)}
 Sei eine Menge $\chi$ gegeben. Ein Mengensystem $\varUpsilon$ von Mengen $X \subseteq \chi$ wird 
 genau dann $\sigma$-Algebra über $\chi$ genannt, wenn 
 \begin{enumerate}
  \item Ist eine Menge X $\in$ $\varUpsilon$ enthalten, so auch ihr Komplement $X^{c} = \chi \backslash X$.
  \item Falls $X_{i} \in \varUpsilon,$ $i=1,...,\infty$ abzählbares Mengensystem in $\varUpsilon$
  ,dann sind auch $\cup_{i=1}^{\infty}X_{i} \in \varUpsilon$ und $\cap_{i=1}^{\infty}X_{i} \in \varUpsilon$ in 
  $\varUpsilon$ enthalten.
 \end{enumerate}

\end{Definition}

Kurz, jede $\sigma$-Algebra ist abgeschlossen unter Komplementbildung und abzählbaren Vereinigungen oder
Schnitten. 

\begin{Definition}\textbf{(Borelmengen)}
 Sei $\chi = \R^{n}$, die Borelmengen $B_{n}$ sind die kleinsten $\sigma$-Algebren, die alle 
 offenen Intervalle 
 $$
 \textit{\{}(x_{1},...,x_{n})\in \R^{n} | \forall i \in \textit{\{}1,...,n\textit{\}}: x_{i} \in (a_{i},b_{i})\textit{\}}
 $$
 für alle $a_{i},b_{i} \in \R$. Bemerke, dass $B_{n}$ überabzählbar ist. 
\end{Definition}

\begin{Definition}\textbf{(Maß- und Wahrscheinlichkeitsraum)}
 Ein messbarer Raum ist ein Tupel $(\chi,\varUpsilon)$. Dabei ist $\chi$ das Universum und 
 $\varUpsilon$ $\sigma$-Algebra über $\chi$. Ein Wahrscheinlichkeitsraum ist ein Tripel $(\chi,\varUpsilon,P)$,
 wobei $P$ ein Wahrscheinlichkeitsmaß auf $\chi$ ist. D.h. $P: \varUpsilon \rightarrow [0,1]$, sodass
 $P(\chi) = 1$ und für disjunkte abzählbare Vereinigungen $X_{i} \in \varUpsilon$, $i= 1,...\infty$ gilt
 $$
 P(\cup_{i=1}^{\infty}X_{i}) = \sum_{i=1}^{\infty}P(X_{i}).
 $$
 \end{Definition}

\begin{Definition}\textbf{(Messbarkeit)}
 Sei $(\chi,\varUpsilon)$ messbarer Raum. Eine reellwertige Funktion $g: \chi \rightarrow \R$
 heisst $\varUpsilon$-messbar (oder messbar) genau dann, wenn 
 $$
 \forall z \in \R: \textit{\{} x \in X | g(x) \leq z \textit{\}} \in \varUpsilon.
 $$
 \end{Definition}

\begin{Definition}\textbf{(Zufallsvariable)}
Sei $(\chi,\varUpsilon)$ messbarer Raum. Eine Zufallsvariable ist eine $\chi$-messbare reellwertige
Funktion $f: \chi \rightarrow \R$.
\end{Definition}

Eine Zufallsvariable $Y = f(X)$ induziert also ein Maß $P_{Y}$ auf $\R$, für das die 
$\sigma$-Algebra $A$ die Intervalle der Form {$(-\infty,z)|z \in \R$} enthält. Das Maß 
$P_{Y}$ ist vom Maß $P_{X}$ und $f$ indzuiert. Das bedeutet

$$
\forall Y \in B_{1}: P_{Y}(Y) := P_{X}(\textit{\{} x \in X | f(x) \in Y \textit{\}}).
$$

\begin{Definition}\textbf{(Verteilungsfunktion und Dichte)}
Für eine Zufallsvariable X heißt die durch 
$$
F_{X}(x) := P_{X}(X \leq x)
$$
definierte Funktion $F_{X}: \R \rightarrow [0,1]$ Verteilungsfunktion von $X$.
Die Funktion $f_{X}: \R \rightarrow \R$ wird Dichte genannt, falls 
$$
\forall z \in \R: F_{X}(z) = \int_{x \leq z} f_{X}(x) dx. 
$$
\end{Definition}

Für weitere Betrachtungen ist Erwartung einer Zufallsvariablen von essentieller Bedeutung. 

\begin{Definition}\textbf{(Erwartungswert)}
 Sei $f: \chi \rightarrow \R $ messbare Funktion. Der Erwartungswert $E_{X}[f(X)]$ von $f$
 über die Wahrscheinlichkeit von x wird durch 
 $$
 E_{X}[f(X)] := \int_{\R}f(x)dF_{X}(x)
 $$
 definiert. Der Erwartungswert ist nur dann definiert, wenn $\int_{\R}|f(x)|dF_{X}(x) < \infty$.
\end{Definition}

\begin{Definition}\textbf{(Varianz)}
 Die Varianz $Var(X)$ einer Zufallsvariable $X$ ist definiert durch 
 $$
 Var(X) := E_{X}[(X-\mu)^{2}] = E_{X}[X^{2}] - \mu^{2},
 $$
 wobei $\mu = E_{X}[X]$ der Erwartungswert der Zufallsvariable $X$ ist.  
\end{Definition}

\begin{Definition}\textbf{(Produktraum)}
 Seien zwei Maßräume $(\chi,\varUpsilon)$ und $(\varphi,\Phi)$ gegeben. Definiere den 
 Produktraum durch $(\chi \times \varphi,\varUpsilon \times \Phi)$. Hierbei bezeichnet
 $\varUpsilon \times \Phi$ die kleinste $\sigma$-Algebra welche die Mengen $\textit{\{}X \times Y | X \in \varUpsilon, Y \in \Phi\textit{\}}$.
 enthält.
 \end{Definition}

\begin{Definition}\textbf{(Marginal und bedingte Wahrscheinlichkeiten)}
  Sei $(\chi \times \varphi,\varUpsilon \times \Phi, P_{XY})$ der Produktraum von $X$ und $Y$.
  Das Marginalwahrscheinlichkeitsmaß $P_{X}$ ist dann durch 
  $$
  \forall X \in \varUpsilon: P_{X}(X) := P_{XY}(X \times \varphi)
  $$
  definiert.
  Sei $Y \in \Phi$ und $P_{Y}(Y) > 0$, dann ist das bedingte Wahrscheinlichkeitsmaß $P_{X|Y \in Y}$ durch
  $$
  \forall Y \in \varUpsilon: P_{X|Y}(X) := \frac{P_{XY}(X \times Y)}{P_{Y}(Y)}
  $$
  gegeben.
\end{Definition}

\begin{Definition}\textbf{Unabhängigkeit}
  Zwei Zufallsvariablen $X$ und $Y$ werden genau dann unabhängig genannt, wenn 
  $$
  \forall X \in \varUpsilon: \forall Y \in \Phi: P_{XY}(X \times Y) = P_{X}(X)P_{Y}(Y).
  $$
  In diesem Fall genügen die Marginalverteilungen um den gesamten Produktraum zu definieren.
\end{Definition}
  
  Im Folgenden schreibe \textbf{X}, falls \textbf{X} eine Folge $(X_{1},...,X{n})$ von Zufallsvariablen
  definiert. Eine solche Folge kann je nach Kontext entweder als Zeilen- oder als Spaltenvektor interpretiert 
  werden. Ein Element des Universums $\chi^{n}$ wird dann durch ein n-Tupel \textbf{x} beschrieben.
  Sei $\textbf{x} = (x_{1},...,x_{n})$ ein solches n-Tupel, dann verstehe $x \in \textbf{x}$
  als $\exists i \in \textit{\{} 1,...,n \textit{\}}: x_{i} = x$. 

\begin{Definition}\textbf{(Erwartungswert einer n-dimensionalen Zufallsvariable)}
 Seien $\textbf{X} = (X_{1},...,X_{n})$ n Zufallsvariablen mit gemeinsamem Wahrscheinlichkeitsmaß $P_{X}$, 
 dann ist die Erwartung $E_{\textbf{X}}[\textbf{X}]$ durch das n-Tupel
 $$
 E_{\textbf{X}}[\textbf{X}] = (E_{X_{1}}[X_{1}],...,E_{X_{n}}[X_{n}])
 $$
 gegeben.
\end{Definition}

\begin{Definition}\textbf{(Kovarianz und Konvarianzmatrix)}
 Seien $X$ und $Y$ zwei Zufallsvariablen mit gemeinsamem Wahrscheinlichkeitsmaß $P_{XY}$,
 dann ist die Kovarianz $Cov(X,Y)$ durch 
 $$
 Cov(X,Y) := E_{XY}[(X-\mu)(Y-\nu)]
 $$
 definiert, wobei $\mu = E_{X}[X]$ und $\nu = E_{Y}[Y]$. Es ist leicht einzusehemn,dass $Cov(X,X) = Var(X)$
 Sei $\textbf{X} = (X_{1},...,X_{n})$ eine Folge von n Zufallsvariablen und $\textbf{Y} = (Y_{1},...,Y_{n})$
 eine weitere solche Folge mit gemeinsamer Dichte $P_{XY}$, dann ist die $n \times m$ Kovarianzmatrix
 \textbf{Cov(X,Y)} definiert durch
 $$
 \textbf{Cov(X,Y)} := 
 \begin{pmatrix}
  Cov(X_{1},Y_{1}) 	& ... 	& Cov(X_{1},Y_{m})  	\\
  . 			& ... 	& .  			\\
  . 			& ... 	& .			\\
  . 			& ... 	& .		  	\\
  Cov(X_{n},Y_{1}) 	& ...	& Cov(X_{n},Y_{m}) 
 \end{pmatrix}
 $$
 Falls $\textbf{X} = \textbf{Y}$ $\textbf{Cov(X,X)} = \textbf{Cov(X)}$
 \end{Definition}
 
 \subsection{Eigenschaften von Zufallsvariablen}
 
 \begin{Satz}\textbf{(Erwartungswert von Summen und Produkten)}
  Seien $X$ und $Y$ zwei unabhängige Zufallsvariablen, so gilt
  \begin{equation}
  E_{XY}[X \cdot Y] = E_{X}[X] \cdot E_{Y}[Y], 
  \end{equation}
\begin{equation}
  E_{XY}[X + Y] = E_{X}[X] + E_{Y}[Y], 
  \end{equation}
  immer dann, wenn die Terme auf der rechten Seite existieren. Die zweite Aussage gilt sogar, falls
  $X$ und $Y$ nicht unabhängig sind. 
 \end{Satz}

 \begin{Satz}\textbf{(Linearität des Erwartungswertes)}
  Für jede n-dimensionale Zufallsvariable $\textbf{X}$, jede Matrix $\textbf{A} \in \R^{m \times n}$
  und jeden stationären Vektor $\textbf{b} \in \R^{m}$ gilt
  $$
  E_{X}[\textbf{AX} + \textbf{b}] = \textbf{A}E_{X}[\textbf{X} + \textbf{b}].
  $$
  \end{Satz}
  
  \begin{Satz}\textbf{Varianz Zerlegung}
   Seien $X$ und $Y$ zwei unabhängige Zufallsvariablen, dann gilt 
   $$
   Var(X + Y) = Var(X) + Var(Y)
   $$
  \end{Satz}
  \begin{Beweis}
   Setze $\mu = E_{X}[X]$ und $\nu = E_{Y}[Y]$. Benutze die Definition der Varianz
   $$
   \begin{array}{c}
     E_{XY}[(X+Y-E_{XY}[X+Y])^{2}] = E_{XY}[((X-\mu)(Y-\nu))^{2}] \\
     = E_{XY}[(X-\mu)^{2}+ 2 \cdot (X-\mu)(Y-\nu) + (Y-\nu)^{2}]  \\
     = E_{X}[(X-\mu)^{2}] + 2E_{XY}[(X-\mu)(Y-\nu)] + E_{Y}[(Y-\nu)^{2}] \\
     = E_{X}[(X-\mu)^{2}] + 2E_{X}[(X-\mu)]E_{Y}[(Y-\nu)] + E_{Y}[(Y-\nu)^{2}] \\
     = Var(X) + Var(Y)
   \end{array}
   $$
  \end{Beweis}

  \begin{Lemma}
   Für jede Zufallsvariable $X$ und jede Konstant $c \in \R$ gilt \\ 
   $Var(cX) = c^{2} \cdot Var(X)$.
  \end{Lemma}

\subsection{Mehrdimensionale Gauß Verteilung}

In diesem Abschnitt werden einige der wichtigsten Eigenschaften der Gaussverteilung zusammengefasst.

\begin{Definition} Sei $\mu \in \R^n$ ein Vektor und $A \in \R^{nxm}$ eine deterministische Matrix. 
Sei weiter $ Y = (Y_{1},...,Y_{m})$ eine Folge von m unabhängigen, normalverteilten Zufallsvariablen
$Y_{i}$ mit Mittewert Null und Einheitsvarianz ($Y_{i} \sim Normal(0,1)$). Dann wird $X = AY + \mu$ normal-
oder gaußverteilt mit Erwartungswert $E_{X}[X] = \mu$ und Kovarianzmatrix $Cov(X) = \varSigma = AA^{'}$ genannt.
Da das Maß $P_{X}$ eindeutig durch diese beiden Größen beschrieben wird schreiben wir im Weiteren auch $Y \sim Normal(\mu , \varSigma)$.
\end{Definition}

\begin{Satz} Falls $X \sim Normal(\mu,\varSigma)$, dann besitzt $X$ genau dann eine Dichte $f_X$, wenn 
$\varSigma$ positiv definit ist. Die Dichte $f_{X}$ ist gegeben durch 
\begin{equation}
f_{X}(x) = \frac{1}{(2\pi)^{n/2}|\varSigma|^{\frac{1}{2}}}\exp(-\frac{1}{2}(x-\mu)^{T}\varSigma^{-1}(x-\mu)) 
\end{equation}

\end{Satz}

\begin{Satz}
 Sei $X \sim Normal(\mu,\varSigma)$ eine n-dimensional normalverteilte Zufallsvariable,
 $A \in R^{mxn}$ stationäre Matrix und $b \in \R^m$ stationärer Vektor. Dann ist auch die Zufallsvariable 
 $Y = AX + b$ normalverteilt mit $Y \sim Normal(A\mu + b, A\varSigma A^{T})$.
\end{Satz}

\begin{Satz}
 Angenommen $P_{X|Y=y}=Normal(Xy,\Gamma)$ ist normalverteiltes Wahrscheinlichkeitsmaß, wobei 
 $X \in \R^{mxn}$ und $\Gamma \in \R^{mxm}$ stationäre Matrizen für alle Werte $y \in \R^{n}$ sind. Falls
 $P_{Y} = Normal(\mu,\varSigma)$ normalverteiltes Wahrscheinlichkeitsmaß ist, so gilt
 
 \begin{equation}
 P_{Y|X=x} = Normal(\Psi(X^{T}\Gamma^{-1}x+\varSigma^{-1}\mu),\Psi).
 \end{equation}
 \begin{equation}
  P_{X} = Normal(X\mu,\Gamma+X\varSigma X^{T}).
 \end{equation}
 ,wobei $\Psi = (X^{T}\Gamma^{-1}X+\varSigma^{-1})^{-1}$
\end{Satz}

\begin{Beweis}
 Nach Satz () wissen wir, dass 
$$
  f_{Y|X=x(y)} = \frac{f_{X|Y=y}f_{Y}(y)}{\int_{\R^n}f_{X|Y=y^{'}(x)}f_{Y}(y^{'})dy^{'}} 
 = \frac{f_{X|Y=y}(x)f_{Y}(y)}{f_{X}(x)}.
$$

 Es fällt auf, dass der Nenner unabhängig von $y$ ist. Betrachte nun deshalb zunächst den Zähler.
 Mithilfe von Definition ist Letzteres gegeben durch 
 $$ 
 c\cdot exp(-\frac{1}{2}((x-Xy)^{T}\Gamma^{-1}(x-Xy)+(y-\mu)^{T}\varSigma^{-1}(y-\mu))),
 $$

 
 wobei $c = (2\pi)^{\frac{-m+n}{2}}|\Gamma|^{-\frac{1}{2}}|\Gamma|^{-\frac{1}{2}}$ unabhängig von 
 $x$ und $y$ ist.
 Diesen Ausdruck wiederum können wir umschreiben als 
 
 $$
 c \cdot exp(-\frac{1}{2}((y-x)^{T}C(y-c)+d(x))), 
 $$
 mit 
 
 $$
 C = X^{T}\Gamma^{-1}X+\varSigma^{-1},
 $$
 
 $$
 Cc = X^{T}\Gamma^{-1}X+\varSigma^{-1}\mu,
 $$
 
 $$
 d(x) = (x-X\mu)^{T}(\Gamma+X\varSigma X^{T})^{-1}(x-X\mu).
 $$
 
 Da $d(x)$ als Funktion nicht von $y$ abhängt, kann der Term $exp(-\frac{1}{2}d(x))$ mit in die
 Konstante c gezogen werden und somit folgt die erste Gleichung des Satzes indem $\Psi:=C^{-1}$
 gesetzt wird.\\
 Um die Zweite Aussage zu zeigen kann die Definition von $f_{X}(x)$ benutzt werden, d.h,
 
 $$
 \begin{array}{c}
  f_{X}(x) = \int_{\R^{n}}c \cdot exp(-\frac{1}{2}((y^{'}-c)^{T}C(y^{'}-c)+d(x))dy^{'} \\
 = c \cdot exp(-\frac{1}{2}d(x)) \cdot \int_{\R^{n}}exp(-\frac{1}{2}((y^{'}-c)^{T}C(y^{'}-c))dy^{'}\\
 = c \cdot exp(-\frac{1}{2}d(x)) \cdot (2\pi)^{\frac{n}{2}}|C|^\frac{1}{2} = c^{'} \cdot exp(-\frac{1}{2}d(x))\\
 = c^{'} \cdot exp(-\frac{1}{2}(x-X\mu)^{T}(\Gamma+X\varSigma X^T)^{-1}(x-X\mu)),
 \end{array}
 $$
 wobei die dritte Zeile aus der Definition und der Tatsache folgt, dass sich Wahrscheinlichkeitsdichten
 zu Einer zusammenfassen lassen. Dies zeigt die zweite Aussage. \Square
\end{Beweis}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \newpage  % neuer Abschnitt auf neue Seite, kann auch entfallen
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Faktorgraphen}
Ein Faktorgraph ist ein bipartiter Graph, der beschreibt wie eine globale Funktion in Abhängigkeit von 
verschiedenen Variablen und Faktoren durch ein Produkt von lokalen Funktionen ausgedrückt werden kann.

\subsection{Allgemeines}
In Faktorgraphen wird zwischen zwei Typen von Knoten unterschieden: Die einen Knoten, welche mit Variablen 
identifiziert werden (nicht ausgefüllte Knoten) und die Anderen, welche mit lokalen Funktionen identifiziert werden 
(ausgefüllte Knoten).  Kanten verbinden Variablenknoten $x_{i}$ und Funtionenknoten $f$ genau dann, wenn 
$x_{i}$ Argument von $f$ ist. \\

Sei $X = \{ x_{i} \}_{i \in \N}$ eine Menge von Variablen bzgl. der Indexmenge $N = \{ 1,2,3,...,n \}$. 
Falls $E$ triviale Teilmenge von N ist, so bezeichne mit $X_{E}$ die Teilmenge von $X$, welche durch E induziert wird. 
Für jedes $ i \in N $ nehme die Variable $x_{i}$ Werte aus dem Alphabet $A_{i}$ an. Desweiteren wird angenommen,dass
$A_{i}$ für alle $i \in N$ stets endlich ist. Bezeichne eine bestimmte Belegung der Variablen aus $X$ als Konfiguration 
der Variablen. Diese Konfigurationen können als Kartesisches Produkt $W = \prod_{i \in N}A_{i}$, den sogenannten Konfigurationsraum
verstanden werden. 

Ein Element $w = (w_{1},...,w_{n}) \in W$, mit $w_{i} \in A_{i}$ ist entspricht der Varaiblenbelegung
$x_{1} = w_{1},...,x_{n} = w_{n} $. \\

Im weiteren sind Funktionen mit Urbild $W$ von besonderem Interesse. Sei $g: W \rightarrow R$ eine solche Funktion, auch gloabele
Funktion genannt. Im Moment beziehe sich der Wertebereich auf die Reellen Zahlen. Im Allgemeinen sei jedoch jeder beliebige Semiring erlaubt. \\

%Beispiel einfügen

\subsection{Bayssche Netwerke}

Bayssche Nezwerke sind gerichtete, azyklische graphische Modelle auf einer Menge von Zufallsvariablen. 
Jeder Knoten $v$ eines Baysschen Netwerkes wird mit einer Zufallsvariable assoziert. Bezeichnet $a(v)$, die Menge
der Vorgänger des Knotens $v$, so hat die Wahrscheitsverteilung des Baysschen Netzwerkes die Form

\begin{equation}
 p(v_{1},v_{2},...,v_{n}) = \prod_{i=1}^n p(v_{i}|a(v_i))
\end{equation}

Falls $a(v_i) = \varnothing $ (d.h. $v_i$ hat keine Vorgänger), so setze $p(v_i| \varnothing) = p(v_i)$.
Figur \textbf{FIGUR EINFÜGEN} zeigt beispielsweise eine Bayssches Netwerk, welches die Faktorisierung 
$$
p(v_1,v_2,v_3,v_4,v_5) = p(v_1|v_2)p(v_2)p(v_3|v_2,v_4)p(v_4)p(v_5|p_4)
$$
beschreibt. 

\subsection{Sum-Product Algorithmus}

Sei $g(X)$ globale Funktion über die Variablen der Menge $X = \{ x_i : i \in N \}$, wobei Variable $x_i$ Werte
der endlichen Menge $A_i$ annimmt.
In diesem Abschnitt wird eine Algorithmus beschrieben, um die marginal Funktionen 

\begin{equation}
 G_i(x_i) = \sum_{x_1 \in A_1,...,x_{i-1} \in A_{i-1},x_{i+1} \in A_{i+1},...,x_n \in A_n} g(x_1,...,x_n)
\end{equation}

für Variablen $x_i, i \in N $ zu berechnen. Im Weiteren sei $\sum_{x_i} f(x_i) = \sum_{x_i \in A_i} f(x_i)$ und genauso
sei für eine Teilmenge $J \subset N$ mit $\sum_{x_i; i \in J}$ f(X) die Summe über alle möglichen Konfigurationen der Variablen $x_i$
über $J$ gemeint. Damit gilt $G_i(x_i) = \sum_{x_j;j\in N \ \{i\}}g(X)$.
Die Definition der marginalen Funktion $G$ kann nun auf eine Teilmenge $J$ von $N$ ausgeweitet werden.

\begin{equation}
 G_i(x_i) = \sum_{x_i; i \in N \ J} g(X).
\end{equation}

Falls $g(x_1,...,x_n)$ eine Wahrscheinlichkeitsverteilung beschreibt, so ist $G_i(x_i)$ die Marginalverteilung und 
$G_{J}(X_J)$ die gemeinsame Wahrscheinlichkeitsverteilung der Variablen über die Indexmenge $J$.
\\
Ist die Anzahl $n$ der Argumente von g klein, so nutze eine alternative Kurzschreibweise für die Marginalfunktionen. 
Schreibe statt einem Argument $x_i$ von $g$ ein $+$ um anzudeuten, dass über diese Variable summiert wird.

\subsection{Funktionsweise des Algorithmus}

Der Sum-product Algorithmus operiert mithilfe einer "message passing" Porzedur, die Produukte von lokalen 
Funktionen entlangg der Pfade des Faktorgraphen aufsammelt. Es wird angenommen,dass dieser Graph ein Baum ist, d.h.
dass dieser Graph keine Kreise enthält. Die Beschreibung des Algorithmus kann durch die Annahme, dass jeder Knoten wie ein
Prozessor Nachrichten über Kanten übermittelt und empfängt. \\

Für diese vereinfachte Betrachtung arbeitet der Algorithmus wie folgt. Die Basisoperation an jedem Knoten ermittlet
das Produkt aller eingehenden Nachrichten an diesem Knoten. Für Knoten, die eine Menge von Variablen darstellen, wird dieses Produkt
um die zugehörigen lokalen Funktionen erweitert. Die so ermittelten Produkte werden dann mit dem Vorbehalt, dass
Nachrichten über ausgehnde Knoten keine Faktoren enthalten, über die ausgehenden Kanten übermittelt. Da vorrausgesetzt
wurde, dass der Faktorgraph keine Kreise enthält, enthält das Produkt der ausgehenden Nachrichten einer Kante und der empfangenen
Nachrichten dieser Kante alle Faktoren der globalen Funktion. \\

Diese sogenannte "message-passing" Prozedur wird von den Blättern des Faktorgraphs aus gestartet und iteriert über alle
Knoten des Graphen. An Blättern, die Variablenmengen darstellen entspricht die ausgehende Nachricht eine Representation der lokalen 
Funktion dieses Knotens. An Blättern, die eine Variable darstellen entspricht sie hingegen der Indikatorfunktion.
Alle anderen Knoten des Graphen warten zunächst bis sie genügend Nachrichten gesammelt haben um eine ausgehende 
Nachricht zu produzieren. Genauer soll das heißen, sie warten solange, bis an jeder bis auf einer eingehenden Kante Nachrichten
empfangen wurden. Tritt dieser Fall ein, so wird das Produkt aller eingehenden Nachrichten mit der lokalen Funktion gebildet und über die freie Kante übermittelt.
Wird an dieser übrig gebliebenen Kante eine Nachricht empfangen, so werden die Produkte der zugehörigen lokalen Funktion über alle
anderen ausgehnden Kanten versendet. Diese Prozedur wird in Figur \textbf{FIGUR EINFÜGEN!!!} illustriert.\\

Dieser Algorithmus wird dann effektiv, wenn man beachtet, dass von lokalen Funktionen über Pfade gesammelte Produkte
marginalisiert werden können. D.h., dass nicht alle Variablen entlang einer Kante beachtet werden müssen. Im Allgemeinen
muss eine Variable beachtet werden, wenn sie Argument einer nachfolgenden lokalen Funktion ist. Andernfalls kann
sie vernachlässigt werden. \\

Figur \textbf{FIGUR EINFÜGEN!!!} zeigt das Fragment eines Faktorgraphen. Die Update Regeln für dieses Fragment ergeben sich dann also

\begin{equation}
 \mu_{x \rightarrow A}(x) = \mu_{B \rightarrow x}(x) \cdot \mu_{C \rightarrow x}(x)  
\end{equation}

\begin{equation}
 \mu_{A \rightarrow x}(x) = \sum_{y,z} f_A(x,y,z) \cdot \mu_{y \rightarrow A}(x) \cdot \mu_{z \rightarrow A}(x)
\end{equation}

\begin{equation}
 F_x(x) = \mu_{x \rightarrow A}(x) \cdot \mu_{A \rightarrow x}(x)
\end{equation}

\subsection{Belief Propagation in Baysschen Netzwerken}

\text{FIGUR EINFÜGEN!!!}\\
Die Verteilungsfunktion () eines Bayssschen Netzwerkes erlaubt eine intuitive Umformulierung zur Representation
eines Faktorgraphen. Eine zu einem einzigen Faktor gehörende lokale Funktion in (), hat die Form $f(x|a(x))$, wobei $a(x)$ die Menge der
Nachfolger von x im zugehörigen Baysschen Netzwerk ist. In Faktorgraphen wurden Nachfolgerknoten durch Pfeile gekennzeichnet.
Diese Pfeile erlauben es uns einen Faktorgraphen ebenso als Bayssches Netzwerk ansehen zu können.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \newpage  % neuer Abschnitt auf neue Seite, kann auch entfallen
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Expection Propagation}
In diesem Kapitel werden rekursive Approximationstechniken beschrieben, um die KL-Divergenz zwischen Posterior und Approximation 
zu minimieren. Das sogenannte "Assumed-density Filtering" ist eine schnelle Methode auf diesem Gebiet. "Expectation Propagation" oder kurz
EP ist eine Erweiterung des "Assumed-density Filtering" um Situationen stapelweise zu verarbeiten. Es hat höhere Genauigkeit als
das "Assumed-density Filtering" und andere vergleichbare Methoden um Schlussfolgerungen zu approximieren. 

\subsection{Assumed-density Filtering}

Dieser Abschnitt fasst die Idee des "Assumed-density Filtering" (ADF) zusammen um die Grundlagen für die Methode des "Expectation Propagation" zu
schaffen. "Assumed-density Filtering" ist eine der grundlegenden Techniken, um Posterior in Baysschen Netzwerken und anderen
statistischen Modellen zu approximieren. \\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \newpage  % neuer Abschnitt auf neue Seite, kann auch entfallen
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Das Trueskill Verfahren}
Das Trueskill Verfahren ist ein Bayssches Ranking Verfahren, dass in seinen Grundzügen eine Erweiterung des
Elo Ranking Systems aus dem Schach ist. 
Dieses neue System beachtet Unsicherheiten in der Bewertung eines Spielers, stellt neue Modelle für ausgeglichene
Spiele auf und kann die Skills eines einzelnen Spielers aus dem Rang eines Teams ermitteln. 
Unsicherheiten werden durch eine Approximierung des message passing in faktorgraphen simuliert.  

\subsection{Der Trueskill Faktorgraph}

\subsection{Aprroximieren des Message Passing}

  % Literaturverzeichnis (beginnt auf einer ungeraden Seite)
  \newpage

\begin{thebibliography}{Lam00}
 
\end{thebibliography}
 
      
  % ggf. hier Tabelle mit Symbolen 
  % (kann auch auf das Inhaltsverzeichnis folgen)

\newpage
  
 \thispagestyle{empty}


\vspace*{8cm}


\section*{Erklärung}

Hiermit versichere ich, dass ich diese Arbeit selbständig verfasst und keine anderen, als die angegebenen Quellen und Hilfsmittel benutzt, die wörtlich oder inhaltlich übernommenen Stellen als solche kenntlich gemacht und die Satzung des Karlsruher Instituts für Technologie zur Sicherung guter wissenschaftlicher Praxis in der jeweils gültigen Fassung beachtet habe. \\[2ex] 

\noindent
Ort, den Datum\\[5ex]

% Unterschrift (handgeschrieben)



\end{document}

